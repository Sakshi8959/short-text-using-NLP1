{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecf956b0-4c50-4957-bd5b-b618dedd68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2465cf9e-4bb7-409e-a2e1-dcbab249313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\" I am Sakshi Dubey I am pursuing a Bachelor of Engineering from Acropolis Institute of Technology and Research in Specialisation  in Data Science Branch I am learning to improve my skills and getting experience \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d889b156-7df6-4c7d-a459-3cd12b23b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71cd4faf-4fe5-44be-9772-0cd6554a9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(sample_text)\n",
    "words = [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a0f9f-44e9-4352-a948-3f6ff57e81df",
   "metadata": {},
   "source": [
    "Lowercasing and removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dce9fac6-4edc-41c7-afca-27a5fe302be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_words = [[re.sub(r'[^a-zA-Z0-9]','',words.lower()) for words in sentence] for sentence in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c57207-199d-4dc0-ab0c-ff4d53e18691",
   "metadata": {},
   "source": [
    "Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a7f6f52-b9c7-4b0a-a5d9-0e165f833554",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [[words for words in sentence if words not in stop_words] for sentence in cleaned_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e1b9a-8e25-4b04-9539-c380fcb37aaa",
   "metadata": {},
   "source": [
    "Stemming And Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c098df5-c6c2-4ac1-bf41-36f55b5c8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac8945d4-fc2c-478c-baa1-8d4abc7d2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [[stemmer.stem(words) for words in sentence] for sentence in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3b5e182-1dd5-4ec6-9fee-f5830868dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = [[lemmatizer.lemmatize(words) for words in sentence] for sentence in filtered_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9d560-0fff-4738-bb95-4e68a5dddeb6",
   "metadata": {},
   "source": [
    "Printing Processed Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e28aed4-d359-45cb-867c-59c27259cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original Sentence\n",
      " I am Sakshi Dubey I am pursuing a Bachelor of Engineering from Acropolis Institute of Technology and Research in Specialisation  in Data Science Branch I am learning to improve my skills and getting experience\n",
      "\n",
      "Processed Sentence (Lemmatized):\n",
      "sakshi dubey pursuing bachelor engineering acropolis institute technology research specialisation data science branch learning improve skill getting experience\n"
     ]
    }
   ],
   "source": [
    "print(\"original Sentence\")\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "print(\"\\nProcessed Sentence (Lemmatized):\")\n",
    "for sentence in lemmatized_words:\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96725dd-7824-49a6-b484-695d52a30d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f11268-2a5b-4362-a04d-01a47d3dda7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259cf770-9534-491e-8b87-ea3c30b64ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23fc0c-b14f-4f8c-bf38-a4abd49ec4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
